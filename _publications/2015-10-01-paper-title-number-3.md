---
title: "Learning Precise, Contact-Rich Manipulation through Uncalibrated Tactile Skins"
collection: publications
category: conferences
excerpt: 'ViSk builds on BAKU, a SOTA policy architecture, and AnySkin â€“ a magnetic tactile sensor. We present comprehensive evaluations on four tasks requiring mm-scale precision: Plug insertion, USB insertion, Card swiping, and Book retrieval, and see an average improvement of ~27.5% when using ViSk over vision-only policies across the four tasks.

Additionally, the most exciting part of ViSk is the extent of generalizability of learned policies; it can also perform really well in both unseen spatial configurations of the environment as well as unseen variants of the grasped objects.'
date: 2024-10-22
venue: 'Oct 22' 
# venue: 'website: [Click here](https://visuoskin.github.io/)'
# slidesurl: 'http://academicpages.github.io/files/slides1.pdf'
paperurl: 'https://arxiv.org/pdf/2410.17246'
citation: 'Pattabiraman, Venkatesh, Yifeng Cao, Siddhant Haldar, Lerrel Pinto, and Raunaq Bhirangi. "Learning Precise, Contact-Rich Manipulation through Uncalibrated Tactile Skins." arXiv preprint arXiv:2410.17246 (2024).'
---
